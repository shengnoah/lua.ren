---
layout: post
title: evaluate(input_sentence) 
tags: [lua文章]
categories: [topic]
---
<p>详细的记录 evaluate函数的实现。<br/>解决报错</p>
<figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br/><span class="line">2</span><br/><span class="line">3</span><br/><span class="line">4</span><br/><span class="line">5</span><br/><span class="line">6</span><br/><span class="line">7</span><br/><span class="line">8</span><br/><span class="line">9</span><br/><span class="line">10</span><br/><span class="line">11</span><br/><span class="line">12</span><br/><span class="line">13</span><br/><span class="line">14</span><br/><span class="line">15</span><br/><span class="line">16</span><br/><span class="line">17</span><br/><span class="line">18</span><br/><span class="line">19</span><br/></pre></td><td class="code"><pre><span class="line">ValueError                                Traceback (most recent call last)</span><br/><span class="line">&lt;ipython-input-44-2ec1176683f0&gt; <span class="keyword">in</span> &lt;module&gt;</span><br/><span class="line">----&gt; 1 translate(u<span class="string">&#39;Estoy trabajando.&#39;</span>)</span><br/><span class="line"></span><br/><span class="line">&lt;ipython-input-43-4364cc5c7981&gt; <span class="keyword">in</span> translate(input_sentence)</span><br/><span class="line">     49 </span><br/><span class="line">     50 def translate(input_sentence):</span><br/><span class="line">---&gt; 51     results, input_sentence, attention_matrix = evaluate(input_sentence)</span><br/><span class="line">     52 </span><br/><span class="line">     53     <span class="built_in">print</span>(<span class="string">&#34;Input: %s&#34;</span> % (input_sentence))</span><br/><span class="line"></span><br/><span class="line">&lt;ipython-input-43-4364cc5c7981&gt; <span class="keyword">in</span> evaluate(input_sentence)</span><br/><span class="line">     20     decoding_input = tf.expand_dims([out_tokenizer.word_index[<span class="string">&#39;&lt;start&gt;&#39;</span>]], 0)</span><br/><span class="line">     21     <span class="keyword">for</span> t <span class="keyword">in</span> range(max_length_output):</span><br/><span class="line">---&gt; 22         predictions. decoding_hidden, attention_weights = decoder(decoding_input, decoding_hidden, encoding_outputs)</span><br/><span class="line">     23         attention_weights = tf.reshape(attention_weights, (-1,))</span><br/><span class="line">     24         attention_matrix[t] = attention_weights.numpy()</span><br/><span class="line"></span><br/><span class="line">ValueError: too many values to unpack (expected 2)</span><br/></pre></td></tr></tbody></table></figure>

<h3 id="注意看predictions-后面的标点符号"><a href="#注意看predictions-后面的标点符号" class="headerlink" title="注意看predictions 后面的标点符号"></a>注意看predictions 后面的标点符号</h3><p>接收的是一个文本的输入，首先就要转换成适合模型的数据类型。</p>
<figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br/><span class="line">2</span><br/><span class="line">3</span><br/><span class="line">4</span><br/><span class="line">5</span><br/><span class="line">6</span><br/><span class="line">7</span><br/><span class="line">8</span><br/><span class="line">9</span><br/><span class="line">10</span><br/><span class="line">11</span><br/><span class="line">12</span><br/><span class="line">13</span><br/><span class="line">14</span><br/><span class="line">15</span><br/><span class="line">16</span><br/><span class="line">17</span><br/><span class="line">18</span><br/><span class="line">19</span><br/><span class="line">20</span><br/><span class="line">21</span><br/><span class="line">22</span><br/><span class="line">23</span><br/><span class="line">24</span><br/><span class="line">25</span><br/><span class="line">26</span><br/><span class="line">27</span><br/><span class="line">28</span><br/><span class="line">29</span><br/><span class="line">30</span><br/><span class="line">31</span><br/><span class="line">32</span><br/><span class="line">33</span><br/><span class="line">34</span><br/><span class="line">35</span><br/><span class="line">36</span><br/><span class="line">37</span><br/><span class="line">38</span><br/><span class="line">39</span><br/><span class="line">40</span><br/><span class="line">41</span><br/><span class="line">42</span><br/><span class="line">43</span><br/><span class="line">44</span><br/><span class="line">45</span><br/><span class="line">46</span><br/><span class="line">47</span><br/><span class="line">48</span><br/><span class="line">49</span><br/><span class="line">50</span><br/><span class="line">51</span><br/><span class="line">52</span><br/><span class="line">53</span><br/><span class="line">54</span><br/><span class="line">55</span><br/><span class="line">56</span><br/><span class="line">57</span><br/></pre></td><td class="code"><pre><span class="line">def evaluate(input_sentence):</span><br/><span class="line">    attention_matrix = np.zeros((max_length_output, max_length_input)) </span><br/><span class="line">    input_sentence = preprocess_sentence(input_sentence) <span class="comment"># 输入的句子进行预处理。就是分割标点符号/</span></span><br/><span class="line"></span><br/><span class="line">    inputs = [input_tokenizer.word_index[token] <span class="keyword">for</span> token <span class="keyword">in</span> input_sentence.split(<span class="string">&#39; &#39;</span>)] <span class="comment"># text---&gt;id 把句子转换成id</span></span><br/><span class="line">    inputs = keras.preprocessing.sequence.pad_sequences([inputs], maxlen = max_length_input, padding= <span class="string">&#39;post&#39;</span>) <span class="comment"># 把转换成id的向量，进行padding</span></span><br/><span class="line">    inputs = tf.convert_to_tensor(inputs) <span class="comment">#把向量转换为tensor</span></span><br/><span class="line"></span><br/><span class="line">    results = <span class="string">&#39;&#39;</span> <span class="comment"># 定义str, 保存translate的结果</span></span><br/><span class="line"></span><br/><span class="line"><span class="comment">#     encoding_hidden = encoder.initialize_hidden_state()</span></span><br/><span class="line"></span><br/><span class="line">    encoding_hidden = tf.zeros((1, units)) <span class="comment">#初始化encoding_hidden层</span></span><br/><span class="line"></span><br/><span class="line">    encoding_outputs, encoding_hidden = encoder(inputs, encoding_hidden) <span class="comment"># 这一步得到的encoding_hidden就是decoding_hidden 的第一个值</span></span><br/><span class="line">    decoding_hidden = encoding_hidden</span><br/><span class="line"></span><br/><span class="line"></span><br/><span class="line">    decoding_input = tf.expand_dims([out_tokenizer.word_index[<span class="string">&#39;&lt;start&gt;&#39;</span>]], 0) <span class="comment"># 找到开始的第一个输入的id</span></span><br/><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(max_length_output):</span><br/><span class="line">        predictions, decoding_hidden, attention_weights = decoder(decoding_input, decoding_hidden, encoding_outputs)</span><br/><span class="line">        attention_weights = tf.reshape(attention_weights, (-1,))</span><br/><span class="line">        attention_matrix[t] = attention_weights.numpy()</span><br/><span class="line"></span><br/><span class="line">        predicted_id = tf.argmax(predictions[0]).numpy()</span><br/><span class="line"></span><br/><span class="line">        results += out_tokenizer.index_word[predicted_id] + <span class="string">&#39; &#39;</span></span><br/><span class="line"></span><br/><span class="line">        <span class="keyword">if</span> out_tokenizer.index_word[predicted_id] == <span class="string">&#39;&lt;end&gt;&#39;</span>:</span><br/><span class="line">            <span class="built_in">return</span> results, input_sentence, attention_matrix</span><br/><span class="line"></span><br/><span class="line">        decoding_input = tf.expand_dims([predicted_id], 0)</span><br/><span class="line">    <span class="built_in">return</span> results, input_sentence, attention_matrix</span><br/><span class="line"></span><br/><span class="line">def plot_attention(attention_matrix, input_sentence, predicted_sentence):</span><br/><span class="line">    fig = plt.figure(figsize=(10,10))</span><br/><span class="line">    ax = fig.add_subplot(1, 1, 1)</span><br/><span class="line"></span><br/><span class="line">    ax.matshow(attention_matrix, cmap=<span class="string">&#39;viridis&#39;</span>)</span><br/><span class="line"></span><br/><span class="line">    font_dict = {<span class="string">&#39;fontsize&#39;</span>: 14}</span><br/><span class="line"></span><br/><span class="line">    ax.set_xticklabels([<span class="string">&#39;&#39;</span>] + input_sentence,</span><br/><span class="line">                              fontdict = font_dict, rotation = 90)</span><br/><span class="line">    ax.sey_yticklables([<span class="string">&#39;&#39;</span>] + predicted_sentence,</span><br/><span class="line">                              fontdict = font_dict,)</span><br/><span class="line">    plt.show()</span><br/><span class="line"></span><br/><span class="line">def translate(input_sentence):</span><br/><span class="line">    results, input_sentence, attention_matrix = evaluate(input_sentence)</span><br/><span class="line"></span><br/><span class="line">    <span class="built_in">print</span>(<span class="string">&#34;Input: %s&#34;</span> % (input_sentence))</span><br/><span class="line">    <span class="built_in">print</span>(<span class="string">&#34;Predicted translation: %s&#34;</span> % (results))</span><br/><span class="line"></span><br/><span class="line">    attention_matrix = attention_matrix[:len(results.split(<span class="string">&#39; &#39;</span>)),</span><br/><span class="line">                                                       :len(input_sentence.split(<span class="string">&#39; &#39;</span>))]</span><br/><span class="line">    plot_attention(attention_matrix, input_sentence.split(<span class="string">&#39; &#39;</span>), results.split(<span class="string">&#39; &#39;</span>))</span><br/></pre></td></tr></tbody></table></figure>