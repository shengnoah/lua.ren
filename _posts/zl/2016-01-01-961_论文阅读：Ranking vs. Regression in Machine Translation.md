---
layout: post
title: 论文阅读：Ranking vs. Regression in Machine Translation Evaluation 
tags: [lua文章]
categories: [topic]
---
来源：WMT Metrics Shared Task 2008

链接：[Abstract](https://dl.acm.org/citation.cfm?doid=1626394.1626425) or
[PDF](http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=88FB762456FCA0B2C349C3DA3AE7B9CF?doi=10.1.1.158.9744&rep=rep1&type=pdf)

作者：Kevin Duh

单位：UWashington

阅读基础：本文前部为读者普及了Metrics的相关知识，读之即可。另外模型中用到的RankSVM1可以看一下（不看也行，读这篇论文关注的是思想）。

WMT历年来的一个重要任务就是为翻译结果设计评价指标，即WMT Metrics Shared Task.
metrics是给定译文和参考翻译，评价参考翻译的质量。

与之不同的是，quality
estimation（QE）是在不给出参考译文的情况下评估翻译质量。QE只依赖原文和翻译模型，和metrics的数据集是完全不一样的。
QE对应的比赛是WMT Quality Estimation Shared Task.

# metrics的应用细节

Metrics用于在不同翻译系统之间建立比较，作用包括指导单个系统调参，比较系统之间好坏，比较系统的改进（定目标，算进度）等等。

Metrics分为系统级别和句子级别，前者对每一个系统给出一个评价，后者对每一个句子原文及翻译给出一个评价。

Metrics其实是很主观的，所以评价一个metrics的好坏就是看这个指标判断与人类判断的对应程度。
Metrics的一些评价指标通过比较metrics的打分和人类打分的相符程度来评价metrics.

可以参考2入门，里面给出了：

  * Metrics是什么，为什么要做
  * 几个非常基础的metrics的baseline和评价指标
  * 没有给出数据集，但建议看看

# Score-based metrics 和 Ranking-based metrics

Score-based metrics 为每一句译文给出确切的分数，比如最著名的BLEU就是score-based的。 Ranking-based
metrics 对同一原句的不同译文按质量进行排序。 两者的主要区别在于，Score-based metrics 给出的标记是绝对的，Ranking-
based metrics 给出的标记是相对的。

# Ranking-based metrics 的好处

一句话：和人的判断比较相符。

  * 因为是相对标注，所以人更容易给出精确的标注，这样IAA也会比较高。
  * metrics的目的就是比较不同翻译系统的优劣，所以如果可以的话直接给出比较结果就行了，没必要先打绝对评分再比较。

虽然 Ranking-based metrics 不能定量刻画系统之间的差异，但是大部分情况下也够用了。

# Ranking-based metrics 的可行性

如何实现一个 Ranking-based metrics 系统？

考虑metrics语料库的格式，将问题形式化：一共$T$个句子，$r_t$是第$t$个句子的参考译文$(1leq tleq
T)$，而$o_t^{(n)}$是对第$t$个句子的第$n$个翻译$(1leq nleq N)$。Score-based metrics的标签$y_t =
[y_t^{(n)}]_N$是一个$N$维向量，每个维度表示对应译文的得分；而Ranking-based
metrics的标签完全一样，但是只比较标签值的大小。

_（上面描述的形式化过程和原文稍有出入，此处做了简化，但不影响理解全文。）_

常规的score-based
metrics通过$r_t$和$o_t^{(n)}$形成译文的特征向量$x_t^{(n)}$，配合标签$y_t$训练一个回归算法预测打分；而ranking-
based metrics也一样通过回归预测得分，然而只取预测结果的排序。

# 实验

score-based metrics使用RegressionSVM，ranking-based metrics使用RankSVM/RankBoost

提取的特征多是一些基于统计的metrics，所以实验内容也没啥可看的了，无非展示效果，调参，选择特征云云。

# 相关数据集

参考每年最新的WMT任务。

# 建议阅读

使用Ranking-based数据集训练metrics模型的思想最早的工作是3，可以看看。

每年最新的WMT建议参考。

# 参考

  1. **Joachims 2002 KDD** T. Joachims. 2002. Optimizing search engines using clickthrough data. In KDD ↩

  2. **Bojar 2016 WMT Metrics** [WMT Metrics 2016 总结](http://www.statmt.org/wmt16/slides/wmt16-metrics.pdf) ↩

  3. **Ye 2007 WMT Metrics** Y. Ye, M. Zhou, and C.-Y. Lin. 2007. Sentence level machine translation evaluation as a ranking problem. In ACL2007 Wksp on Statistical Machine Translation. ↩