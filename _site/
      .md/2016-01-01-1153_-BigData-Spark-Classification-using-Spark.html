<p>Learning note for <a href="http://www.amazon.com/Machine-Learning-Spark-Nick-Pentreath/dp/1783288515">Machine learning with spark</a>.</p>

<p>Besides, thanks to <a href="https://github.com/apache/incubator-zeppelin">Zeppelin</a>. Although it is not so user-friendly like RStudio or Jupyter, it <strong>really</strong> makes the learning of Spark much easier.</p>

<h1 id="1-data-loading-from-hdfs">1. Data Loading from HDFS</h1>

<p>First, download the data from <a href="https://www.kaggle.com/c/stumbleupon">https://www.kaggle.com/c/stumbleupon</a>.</p>

<p>Then upload data to HDFS:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tail -n +2 train.tsv &gt;train_noheader.tsv
hdfs dfs -mkdir hdfs://tanglab1:9000/user/hadoop/stumbleupon
hdfs dfs -put train_noheader.tsv hdfs://tanglab1:9000/user/hadoop/stumbleupon
</code></pre></div></div>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="n">rawData</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&#34;/user/hadoop/stumbleupon/train_noheader.tsv&#34;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">records</span> <span class="k">=</span> <span class="n">rawData</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">line</span> <span class="k">=&gt;</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&#34;t&#34;</span><span class="o">))</span>
<span class="n">records</span><span class="o">.</span><span class="n">first</span><span class="o">()</span>
</code></pre></div></div>

<h1 id="2-data-process">2. Data Process</h1>
<p>Select the column for label(last column) and Feature(5 ~ last but one column)
Data cleanning and convert NA to 0.0
Save the label and feature in vector into MLlib.</p>

<p><strong>As naive bayesian model do not accept negative input value, convert negtive input into 0</strong></p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">org.apache.spark.mllib.regression.LabeledPoint</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vectors</span>

<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="n">records</span><span class="o">.</span><span class="n">map</span><span class="o">{</span> <span class="n">r</span> <span class="k">=&gt;</span> 
    <span class="k">val</span> <span class="n">trimmed</span> <span class="k">=</span> <span class="n">r</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">replaceAll</span><span class="o">(</span><span class="s">&#34;&#34;&#34;</span><span class="o">,</span> <span class="s">&#34;&#34;</span><span class="o">))</span>
    <span class="k">val</span> <span class="n">label</span> <span class="k">=</span> <span class="n">trimmed</span><span class="o">(</span><span class="n">r</span><span class="o">.</span><span class="n">size</span> <span class="o">-</span> <span class="mi">1</span><span class="o">).</span><span class="n">toInt</span>
    <span class="k">val</span> <span class="n">features</span> <span class="k">=</span> <span class="n">trimmed</span><span class="o">.</span><span class="n">slice</span><span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="n">r</span><span class="o">.</span><span class="n">size</span> <span class="o">-</span> <span class="mi">1</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">d</span> <span class="k">=&gt;</span> 
    	<span class="k">if</span> <span class="o">(</span><span class="n">d</span><span class="o">==</span><span class="s">&#34;?&#34;</span><span class="o">)</span> <span class="mf">0.0</span> <span class="k">else</span> <span class="n">d</span><span class="o">.</span><span class="n">toDouble</span><span class="o">)</span>
    <span class="nc">LabeledPoint</span><span class="o">(</span><span class="n">label</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="n">features</span><span class="o">))</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">nbData</span> <span class="k">=</span> <span class="n">records</span><span class="o">.</span><span class="n">map</span><span class="o">{</span> <span class="n">r</span> <span class="k">=&gt;</span> 
    <span class="k">val</span> <span class="n">trimmed</span> <span class="k">=</span> <span class="n">r</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">replaceAll</span><span class="o">(</span><span class="s">&#34;&#34;&#34;</span><span class="o">,</span> <span class="s">&#34;&#34;</span><span class="o">))</span>
    <span class="k">val</span> <span class="n">label</span> <span class="k">=</span> <span class="n">trimmed</span><span class="o">(</span><span class="n">r</span><span class="o">.</span><span class="n">size</span> <span class="o">-</span> <span class="mi">1</span><span class="o">).</span><span class="n">toInt</span>
    <span class="k">val</span> <span class="n">features</span> <span class="k">=</span> <span class="n">trimmed</span><span class="o">.</span><span class="n">slice</span><span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="n">r</span><span class="o">.</span><span class="n">size</span> <span class="o">-</span> <span class="mi">1</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">d</span> <span class="k">=&gt;</span> 
	    <span class="k">if</span><span class="o">(</span><span class="n">d</span><span class="o">==</span><span class="s">&#34;?&#34;</span><span class="o">)</span> <span class="mf">0.0</span> <span class="k">else</span> <span class="n">d</span><span class="o">.</span><span class="n">toDouble</span><span class="o">).</span><span class="n">map</span><span class="o">(</span> <span class="n">d</span><span class="k">=&gt;</span> <span class="k">if</span><span class="o">(</span><span class="n">d</span><span class="o">&lt;</span><span class="mf">0.0</span><span class="o">)</span> <span class="mf">0.0</span> <span class="k">else</span> <span class="n">d</span><span class="o">)</span>
    <span class="nc">LabeledPoint</span><span class="o">(</span><span class="n">label</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="o">(</span><span class="n">features</span><span class="o">))</span>
<span class="o">}</span>

<span class="n">data</span><span class="o">.</span><span class="n">cache</span>
<span class="n">data</span><span class="o">.</span><span class="n">count</span>
</code></pre></div></div>

<h1 id="3-model-training">3. Model training</h1>
<p>Import modules required. 
Then define the parameters required by the models.</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">org.apache.spark.mllib.classification.LogisticRegressionWithSGD</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.classification.SVMWithSGD</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.classification.NaiveBayes</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.tree.DecisionTree</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.tree.configuration.Algo</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.tree.impurity.Entropy</span>

<span class="k">val</span> <span class="n">numIterations</span> <span class="k">=</span> <span class="mi">10</span>
<span class="k">val</span> <span class="n">maxTreeDepth</span> <span class="k">=</span> <span class="mi">5</span>
</code></pre></div></div>

<h2 id="31-training-logistic-regression">3.1 Training logistic regression</h2>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="n">lrModel</span> <span class="k">=</span> <span class="nc">LogisticRegressionWithSGD</span><span class="o">.</span><span class="n">train</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">numIterations</span><span class="o">)</span>

<span class="k">val</span> <span class="n">dataPoint</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">first</span>
<span class="k">val</span> <span class="n">prediction</span> <span class="k">=</span> <span class="n">lrModel</span><span class="o">.</span><span class="n">predict</span><span class="o">(</span><span class="n">dataPoint</span><span class="o">.</span><span class="n">features</span><span class="o">)</span>
<span class="k">val</span> <span class="n">trueLabel</span> <span class="k">=</span> <span class="n">dataPoint</span><span class="o">.</span><span class="n">label</span>
</code></pre></div></div>

<h2 id="32-training-svm">3.2 Training SVM</h2>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="n">svmModel</span> <span class="k">=</span> <span class="nc">SVMWithSGD</span><span class="o">.</span><span class="n">train</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">numIterations</span><span class="o">)</span>
</code></pre></div></div>

<h2 id="33-training-the-naive-bayesian-model">3.3 Training the naive bayesian model</h2>
<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="n">nbModel</span> <span class="k">=</span> <span class="nc">NaiveBayes</span><span class="o">.</span><span class="n">train</span><span class="o">(</span><span class="n">nbData</span><span class="o">)</span>
</code></pre></div></div>

<h2 id="34-training-the-decision-model">3.4 Training the decision model</h2>
<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="n">dtModel</span> <span class="k">=</span> <span class="nc">DecisionTree</span><span class="o">.</span><span class="n">train</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="nc">Algo</span><span class="o">.</span><span class="nc">Classification</span><span class="o">,</span> <span class="nc">Entropy</span><span class="o">,</span> <span class="n">maxTreeDepth</span><span class="o">)</span>
</code></pre></div></div>

<h1 id="4-evaluating-the-preformance-of-the-classification-models">4. Evaluating the preformance of the classification models</h1>

<h2 id="41-accuracy">4.1 Accuracy</h2>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="n">lrTotalCorrect</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">{</span> <span class="n">point</span> <span class="k">=&gt;</span>
    <span class="k">if</span><span class="o">(</span> <span class="n">lrModel</span><span class="o">.</span><span class="n">predict</span><span class="o">(</span><span class="n">point</span><span class="o">.</span><span class="n">features</span><span class="o">)</span> <span class="o">==</span> <span class="n">point</span><span class="o">.</span><span class="n">label</span><span class="o">)</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span>
<span class="o">}.</span><span class="n">sum</span>

<span class="k">val</span> <span class="n">svmTotalCorrect</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">{</span> <span class="n">point</span> <span class="k">=&gt;</span>
    <span class="k">if</span><span class="o">(</span> <span class="n">svmModel</span><span class="o">.</span><span class="n">predict</span><span class="o">(</span><span class="n">point</span><span class="o">.</span><span class="n">features</span><span class="o">)</span> <span class="o">==</span> <span class="n">point</span><span class="o">.</span><span class="n">label</span> <span class="o">)</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span>
<span class="o">}.</span><span class="n">sum</span>

<span class="k">val</span> <span class="n">nbTotalCorrect</span> <span class="k">=</span> <span class="n">nbData</span><span class="o">.</span><span class="n">map</span><span class="o">{</span> <span class="n">point</span> <span class="k">=&gt;</span>
    <span class="k">if</span><span class="o">(</span> <span class="n">nbModel</span><span class="o">.</span><span class="n">predict</span><span class="o">(</span><span class="n">point</span><span class="o">.</span><span class="n">features</span><span class="o">)</span>  <span class="o">==</span> <span class="n">point</span><span class="o">.</span><span class="n">label</span> <span class="o">)</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span>
<span class="o">}.</span><span class="n">sum</span>

<span class="k">val</span> <span class="n">dtTotalCorrect</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">{</span> <span class="n">point</span> <span class="k">=&gt;</span>
    <span class="k">val</span> <span class="n">score</span> <span class="k">=</span> <span class="n">dtModel</span><span class="o">.</span><span class="n">predict</span><span class="o">(</span><span class="n">point</span><span class="o">.</span><span class="n">features</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">predicted</span> <span class="k">=</span> <span class="k">if</span><span class="o">(</span><span class="n">score</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="o">)</span> <span class="mi">1</span> <span class="k">else</span>  <span class="mi">0</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">point</span><span class="o">.</span><span class="n">label</span><span class="o">)</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span>
<span class="o">}.</span><span class="n">sum</span>

<span class="k">val</span> <span class="n">lrAccuracy</span> <span class="k">=</span> <span class="n">lrTotalCorrect</span> <span class="o">/</span> <span class="n">data</span><span class="o">.</span><span class="n">count</span>
<span class="k">val</span> <span class="n">svmAccuracy</span>    <span class="k">=</span> <span class="n">svmTotalCorrect</span> <span class="o">/</span> <span class="n">data</span><span class="o">.</span><span class="n">count</span>
<span class="k">val</span> <span class="n">nbTotalAccuracy</span><span class="k">=</span> <span class="n">nbTotalCorrect</span>  <span class="o">/</span> <span class="n">data</span><span class="o">.</span><span class="n">count</span>
<span class="k">val</span> <span class="n">dtTotalAccuracy</span><span class="k">=</span> <span class="n">dtTotalCorrect</span>  <span class="o">/</span> <span class="n">data</span><span class="o">.</span><span class="n">count</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lrAccuracy: Double = 0.5146720757268425
svmAccuracy: Double = 0.5146720757268425
nbTotalAccuracy: Double = 0.5803921568627451
dtTotalAccuracy: Double = 0.6482758620689655
</code></pre></div></div>

<h2 id="42-calculating-the-region-under-the-precision-and-recallpr-and-fp-tproc-curve">4.2 Calculating the region under the Precision and recall(PR) and FP-TP(ROC) curve</h2>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">org.apache.spark.mllib.evaluation.BinaryClassificationMetrics</span>

<span class="k">val</span> <span class="n">metrics</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">lrModel</span><span class="o">,</span> <span class="n">svmModel</span><span class="o">).</span><span class="n">map</span><span class="o">{</span> <span class="n">model</span> <span class="k">=&gt;</span>
    <span class="k">val</span> <span class="n">scoreAndLabels</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">{</span> <span class="n">point</span> <span class="k">=&gt;</span>
        <span class="o">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="o">(</span><span class="n">point</span><span class="o">.</span><span class="n">features</span><span class="o">),</span> <span class="n">point</span><span class="o">.</span><span class="n">label</span><span class="o">)</span>
    <span class="o">}</span>
    <span class="k">val</span> <span class="n">metrics</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">BinaryClassificationMetrics</span><span class="o">(</span><span class="n">scoreAndLabels</span><span class="o">)</span>
    <span class="o">(</span><span class="n">model</span><span class="o">.</span><span class="n">getClass</span><span class="o">.</span><span class="n">getSimpleName</span><span class="o">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">areaUnderPR</span><span class="o">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">areaUnderROC</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div></div>

<p>Naive bayesian need another dataset which have no negative feature. 
And the prediction of naive bayesian is a ratio range from 0 to 1, which needs to be cut to 0 or 1.</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="n">nbmetrics</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">nbModel</span><span class="o">).</span><span class="n">map</span><span class="o">{</span> <span class="n">model</span> <span class="k">=&gt;</span>
    <span class="k">val</span> <span class="n">scoreAndLabels</span> <span class="k">=</span> <span class="n">nbData</span><span class="o">.</span><span class="n">map</span><span class="o">{</span> <span class="n">point</span> <span class="k">=&gt;</span>
        <span class="k">val</span> <span class="n">score</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="o">(</span><span class="n">point</span><span class="o">.</span><span class="n">features</span><span class="o">)</span>
        <span class="o">(</span><span class="k">if</span><span class="o">(</span><span class="n">score</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="o">)</span> <span class="mf">1.0</span> <span class="k">else</span> <span class="mf">0.0</span><span class="o">,</span> <span class="n">point</span><span class="o">.</span><span class="n">label</span><span class="o">)</span>
    <span class="o">}</span>
    <span class="k">val</span> <span class="n">metrics</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">BinaryClassificationMetrics</span><span class="o">(</span><span class="n">scoreAndLabels</span><span class="o">)</span>
    <span class="o">(</span><span class="n">model</span><span class="o">.</span><span class="n">getClass</span><span class="o">.</span><span class="n">getSimpleName</span><span class="o">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">areaUnderPR</span><span class="o">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">areaUnderROC</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div></div>

<p>The prediction of decision tree also have a cutoff.</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="n">dtmetrics</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">dtModel</span><span class="o">).</span><span class="n">map</span><span class="o">{</span> <span class="n">model</span> <span class="k">=&gt;</span>
    <span class="k">val</span> <span class="n">scoreAndLabels</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">{</span> <span class="n">point</span> <span class="k">=&gt;</span>
        <span class="k">val</span> <span class="n">score</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="o">(</span><span class="n">point</span><span class="o">.</span><span class="n">features</span><span class="o">)</span>
        <span class="o">(</span><span class="k">if</span><span class="o">(</span><span class="n">score</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="o">)</span> <span class="mf">1.0</span> <span class="k">else</span> <span class="mf">0.0</span><span class="o">,</span> <span class="n">point</span><span class="o">.</span><span class="n">label</span><span class="o">)</span>
    <span class="o">}</span>
    <span class="k">val</span> <span class="n">metrics</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">BinaryClassificationMetrics</span><span class="o">(</span><span class="n">scoreAndLabels</span><span class="o">)</span>
    <span class="o">(</span><span class="n">model</span><span class="o">.</span><span class="n">getClass</span><span class="o">.</span><span class="n">getSimpleName</span><span class="o">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">areaUnderPR</span><span class="o">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">areaUnderROC</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div></div>

<p>For all model, the Precision/Recall and FP-TP ROC were summarized as below:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="n">allMetrics</span> <span class="k">=</span> <span class="n">metrics</span> <span class="o">++</span> <span class="n">nbmetrics</span> <span class="o">++</span> <span class="n">dtmetrics</span>
<span class="n">allMetrics</span><span class="o">.</span><span class="n">foreach</span><span class="o">{</span> <span class="k">case</span> <span class="o">(</span><span class="n">m</span><span class="o">,</span> <span class="n">pr</span><span class="o">,</span> <span class="n">roc</span><span class="o">)</span> <span class="k">=&gt;</span>
    <span class="n">println</span><span class="o">(</span><span class="n">f</span><span class="s">&#34;$m, Area under PR: $pr, Area under ROC: $roc&#34;</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div></div>

<p>which gived:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LogisticRegressionModel, Area under PR: 0.7567586293858841, Area under ROC: 0.5014181143280931
SVMModel, Area under PR: 0.7567586293858841, Area under ROC: 0.5014181143280931
NaiveBayesModel, Area under PR: 0.6808510815151734, Area under ROC: 0.5835585110136261
DecisionTreeModel, Area under PR: 0.7430805993331199, Area under ROC: 0.6488371887050935
</code></pre></div></div>

<p><strong>As the preformance is not well enough, some adjustment were required to promote the performance.</strong></p>

<h1 id="5-the-improvement-the-performance-of-model-and-the-optimization-of-the-parameters">5. The improvement the performance of model and the optimization of the parameters.</h1>

<p>Drawbacks for current model:</p>

<ul>
  <li>Only the values were included, not all features.</li>
  <li>No analysis for the features of the data.</li>
  <li>Non-optimized parameter.</li>
</ul>

<h2 id="51-the-standardization-for-features">5.1 The standardization for features</h2>

<p>Try to calculate the mean value and variation for each column of the data</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">org.apache.spark.mllib.linalg.distributed.RowMatrix</span>

<span class="k">val</span> <span class="n">vectors</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">lp</span> <span class="k">=&gt;</span> <span class="n">lp</span><span class="o">.</span><span class="n">features</span><span class="o">)</span>
<span class="k">val</span> <span class="n">matrix</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RowMatrix</span><span class="o">(</span><span class="n">vectors</span><span class="o">)</span>
<span class="k">val</span> <span class="n">matrixSummary</span> <span class="k">=</span> <span class="n">matrix</span><span class="o">.</span><span class="n">computeColumnSummaryStatistics</span><span class="o">()</span>

<span class="k">case</span> <span class="k">class</span> <span class="nc">MatrixInfo</span><span class="o">(</span><span class="n">index</span><span class="k">:</span><span class="kt">Int</span><span class="o">,</span> <span class="n">mean</span><span class="k">:</span> <span class="kt">Double</span><span class="o">,</span> <span class="n">variation</span><span class="k">:</span> <span class="kt">Double</span><span class="o">)</span>
<span class="k">val</span> <span class="n">value_RowMean</span> <span class="k">=</span> <span class="n">matrixSummary</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">toArray</span>
<span class="k">val</span> <span class="n">value_RowVar</span>  <span class="k">=</span> <span class="n">matrixSummary</span><span class="o">.</span><span class="n">variance</span><span class="o">.</span><span class="n">toArray</span>

<span class="k">val</span> <span class="nc">Info</span> <span class="k">=</span> <span class="o">(</span><span class="mi">0</span> <span class="n">to</span> <span class="n">value_RowMean</span><span class="o">.</span><span class="n">length</span><span class="o">-</span><span class="mi">1</span> <span class="n">toList</span><span class="o">).</span><span class="n">map</span><span class="o">{</span><span class="n">i</span> <span class="k">=&gt;</span>
    <span class="nc">MatrixInfo</span><span class="o">(</span><span class="n">i</span><span class="o">,</span> <span class="n">value_RowMean</span><span class="o">(</span><span class="n">i</span><span class="o">),</span> <span class="n">value_RowVar</span><span class="o">(</span><span class="n">i</span><span class="o">))</span>
<span class="o">}.</span><span class="n">toDF</span><span class="o">()</span>

<span class="nc">Info</span><span class="o">.</span><span class="n">registerTempTable</span><span class="o">(</span><span class="s">&#34;Info&#34;</span><span class="o">)</span>
</code></pre></div></div>

<p>These results can be shown directly with Zeppelin:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="k">index</span><span class="p">,</span> <span class="n">mean</span> <span class="k">FROM</span> <span class="n">Info</span>
<span class="k">ORDER</span> <span class="k">BY</span> <span class="k">index</span>
</code></pre></div></div>
<p><img src="http://huboqiang.cn/http://huboqiang.cn//images/2016-03-03-SparkMLlibClassification/FigVar.png" alt="png" /></p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="k">index</span><span class="p">,</span> <span class="n">variation</span> <span class="k">FROM</span> <span class="n">Info</span> 
<span class="k">ORDER</span> <span class="k">BY</span> <span class="k">index</span>
</code></pre></div></div>
<p><img src="/images/2016-03-03-SparkMLlibClassification/FigVar.png" alt="png" /></p>

<p>Let’s see the mean and variation. In the raw format, the distribution of data did not follow the Gaussian distribution. So let’s make a z-score normalization:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">org.apache.spark.mllib.feature.StandardScaler</span>

<span class="k">val</span> <span class="n">scaler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StandardScaler</span><span class="o">(</span>
	<span class="n">withMean</span> <span class="k">=</span> <span class="kc">true</span><span class="o">,</span> 
	<span class="n">withStd</span> <span class="k">=</span> <span class="kc">true</span>
<span class="o">).</span><span class="n">fit</span><span class="o">(</span><span class="n">vectors</span><span class="o">)</span>

<span class="k">val</span> <span class="n">scaledData</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">lp</span> <span class="k">=&gt;</span> 
	<span class="nc">LabeledPoint</span><span class="o">(</span><span class="n">lp</span><span class="o">.</span><span class="n">label</span><span class="o">,</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">lp</span><span class="o">.</span><span class="n">features</span><span class="o">))</span>
<span class="o">)</span>

</code></pre></div></div>

<p>As only logistic regression would be influenced by normalization, here logistic regression will be re-preformed to see the influence of normalization to the result:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="n">lrModelScaled</span> <span class="k">=</span> <span class="nc">LogisticRegressionWithSGD</span><span class="o">.</span><span class="n">train</span><span class="o">(</span><span class="n">scaledData</span><span class="o">,</span> <span class="n">numIterations</span><span class="o">)</span>
<span class="k">val</span> <span class="n">lrTotalCorrectScaled</span> <span class="k">=</span> <span class="n">scaledData</span><span class="o">.</span><span class="n">map</span><span class="o">{</span> <span class="n">point</span> <span class="k">=&gt;</span> 
    <span class="k">if</span><span class="o">(</span><span class="n">lrModelScaled</span><span class="o">.</span><span class="n">predict</span><span class="o">(</span><span class="n">point</span><span class="o">.</span><span class="n">features</span><span class="o">)</span> <span class="o">==</span> <span class="n">point</span><span class="o">.</span><span class="n">label</span><span class="o">)</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span>
<span class="o">}.</span><span class="n">sum</span>
<span class="k">val</span> <span class="n">lrAccuracyScaled</span> <span class="k">=</span> <span class="n">lrTotalCorrectScaled</span> <span class="o">/</span> <span class="n">data</span><span class="o">.</span><span class="n">count</span>
<span class="k">val</span> <span class="n">lrPredictionsVsTrue</span> <span class="k">=</span> <span class="n">scaledData</span><span class="o">.</span><span class="n">map</span><span class="o">{</span> <span class="n">point</span> <span class="k">=&gt;</span> 
    <span class="o">(</span><span class="n">lrModelScaled</span><span class="o">.</span><span class="n">predict</span><span class="o">(</span><span class="n">point</span><span class="o">.</span><span class="n">features</span><span class="o">),</span> <span class="n">point</span><span class="o">.</span><span class="n">label</span><span class="o">)</span>
<span class="o">}</span>
<span class="k">val</span> <span class="n">
</span></code></pre></div></div>
